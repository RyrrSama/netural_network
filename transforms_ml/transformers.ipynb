{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ramkumare\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ramkumare\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'dataclass' from 'c:\\\\Users\\\\Ramkumare\\\\Documents\\\\personal_work\\\\transforms_ml\\\\dataclass.py'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependency imports\n",
    "!pip install torch\n",
    "import torch\n",
    "from importlib import reload\n",
    "\n",
    "# Local imports\n",
    "from utils import *\n",
    "import dataclass\n",
    "reload(dataclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = r\".\\introduction_data.txt\"\n",
    "TRANING_DATA_PERCENTAGE = 90\n",
    "BATCH_SIZE = 4  # how many independent seq will we process in parellel\n",
    "# Note : We dont actually train of model with all the data at once we only train our dataset with chunk of the sample ooof data at once\n",
    "# Because traing the dataset with all data at once will be conputatially heavy.\n",
    "# So our chunk sample  will have max size to be smapled and trained by the model. which is called blocked size\n",
    "BLOCK_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the data set :  198\n"
     ]
    }
   ],
   "source": [
    "data = read_data(DATA)\n",
    "print(\"length of the data set : \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique chars in the data : \n",
      " .HIabcdefhiklmnoprstuvwy\n",
      "Total possibily char we get : 26\n"
     ]
    }
   ],
   "source": [
    "unique_char_list = get_unique_chars(data)\n",
    "vocab_size = len(unique_char_list)\n",
    "print(\"All unique chars in the data : {}\".format(\"\".join(unique_char_list)))\n",
    "print(\"Total possibily char we get : {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is tokenzie?\n",
    "# Converting seq of text to seq of intergen with some seq of vocalbulary\n",
    "\n",
    "# Note need to learn about \"SentencePiece\" tokenzier used by google\n",
    "# Note need to learn about \"tiktoken\" tokenzier used by OpenAI\n",
    "encode_mapper_dict = str_to_int(unique_char_list)\n",
    "decode_mapper_dict = int_to_str(unique_char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3, 12,  1, 15, 25,  1, 16,  5, 15,  9,  1, 12, 20,  1, 19,  5, 15, 13,\n",
      "        22, 15,  5, 19,  9,  1, 12,  1,  5, 15,  1, 18, 12, 18,  9, 14, 12, 16,\n",
      "         9,  1,  8,  9, 23,  9, 14, 17, 18,  9, 19,  0,  4,  1, 11, 17, 18,  9,\n",
      "         1, 25, 17, 22,  1, 24, 12, 14, 14,  1,  6,  9,  1, 22, 20,  9, 10, 22,\n",
      "        14,  1, 10, 17, 19,  1, 17, 21, 11,  9, 19, 20,  1, 21, 17,  1, 15,  5,\n",
      "        13,  9,  1, 21, 11,  9, 12, 19,  1, 14, 12, 10,  9, 20,  1,  6,  9, 21,\n",
      "        21,  9, 19,  2,  0,  3, 22, 15,  5, 16, 20,  1,  5, 19,  9,  1, 11,  5,\n",
      "        19,  8,  1, 21, 17,  1, 22, 16,  8,  9, 19, 20, 21,  5, 16,  8,  1,  5,\n",
      "        16,  8,  1, 20,  9, 14, 10, 12, 20, 11,  1,  6, 22, 21,  1, 23,  9, 19,\n",
      "        25,  1, 13, 12, 16,  8,  1, 11,  9,  5, 19, 21,  9,  8,  1, 20, 18,  9,\n",
      "         7, 12,  9, 20,  1, 12, 16,  1, 21, 11,  9,  1, 24, 17, 19, 14,  8,  2])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor is a multi-dimensioanl matrix containing elemenst of same type\n",
    "tokenize_data = torch.tensor(encode(data, encode_mapper_dict), dtype=torch.long)\n",
    "print(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset for traning and test data\n",
    "traning_data_end_index = int(TRANING_DATA_PERCENTAGE * len(tokenize_data))\n",
    "train_data = tokenize_data[:traning_data_end_index]\n",
    "test_data = tokenize_data[traning_data_end_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([3]) and the target : 12\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12]) and the target : 1\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1]) and the target : 15\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15]) and the target : 25\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25]) and the target : 1\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25,  1]) and the target : 16\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25,  1, 16]) and the target : 5\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25,  1, 16,  5]) and the target : 15\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25,  1, 16,  5, 15]) and the target : 9\n",
      "tensor([12,  1, 15, 25,  1, 16,  5, 15,  9,  1])\n",
      "The context is tensor([ 3, 12,  1, 15, 25,  1, 16,  5, 15,  9]) and the target : 1\n"
     ]
    }
   ],
   "source": [
    "data = dataclass.TextData(train_data, test_data, BLOCK_SIZE, BATCH_SIZE)\n",
    "data.get_context_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b795c85f90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
